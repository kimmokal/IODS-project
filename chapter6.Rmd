# Week 6: Analysis of longitudinal data

```{r, echo=FALSE, message=FALSE}
Sys.setenv(`_R_S3_METHOD_REGISTRATION_NOTE_OVERWRITES_` = "false")
library(ggplot2)
library(GGally)
library(tidyr)
library(dplyr)
library(lme4)
```
```{r, echo=FALSE}
RATSL <- read.table("data/ratsl.csv", sep=",", header=TRUE)
BPRSL <- read.table("data/bprsl.csv", sep=",", header=TRUE)

BPRSL$treatment <- factor(BPRSL$treatment)
BPRSL$subject <- factor(BPRSL$subject)

RATSL$ID <- factor(RATSL$ID)
RATSL$Group <- factor(RATSL$Group)
```

### RATS

In the first part, we analyse the diet effects on the weight of rats using longitudinal analysis and, more specifically, summary measure approach. Let's first have a look at the data set in long form.

```{r, echo=FALSE}
str(RATSL)
```

As opposed to the wide form, now each row is a single observation instead of containing all observations related to a single subject, i.e. rat. The observations are visualized in the plot below, where three groups are separated. Each group corresponds to a different diet.

```{r, fig.width = 6, fig.height = 5, echo=FALSE}
ggplot(RATSL, aes(x = Time, y = Weight, group = ID)) +
  geom_line(aes(linetype = Group)) + scale_y_continuous(name = "Weight (grams)") + theme(legend.position = "top")
```

The most obvious thing to note is that the rats in group 1 weight significantly less at the start. Rats in group 2 are mainly also lighter than those in group 3, apart from one rat in group 2, which is the heaviest of all the studied rats.

Next, the weights are standardized (subtracted by the mean and divided by the standard deviation) at each point in time. Let's see how the standardized weight plot looks like.

```{r, echo=FALSE}
RATSL <- RATSL %>%
 group_by(Time) %>%
 mutate(Stdweight = (Weight - mean(Weight))/sd(Weight)) %>%
 ungroup()
```
```{r, fig.width = 6, fig.height = 5, echo=FALSE}
ggplot(RATSL, aes(x = Time, y = Stdweight, linetype = ID)) +
 geom_line() +
 scale_linetype_manual(values = rep(1:10, times=4)) +
 facet_grid(. ~ Group, labeller = label_both) +
 scale_y_continuous(name = "Standardized weight")
```

This shows how the weights of individual rats develop over time *relative* to the other rats. The average weight gain over time for each group can be examined by plotting the mean profiles for the groups. This is shown in the plot below.

```{r, echo=FALSE, message=FALSE}
n <- RATSL$Time %>% unique() %>% length()
RATSS <- RATSL %>%
 group_by(Group, Time) %>%
 summarise( mean = mean(Weight), se = sd(Weight)/sqrt(n) ) %>%
 ungroup()
```
```{r, fig.width = 6, fig.height = 5, echo=FALSE}
ggplot(RATSS, aes(x = Time, y = mean, linetype = Group, shape = Group)) +
 geom_line() +
 scale_linetype_manual(values = c(1,2,3)) +
 geom_point(size=3) +
 scale_shape_manual(values = c(1,2,3)) +
 geom_errorbar(aes(ymin=mean-se, ymax=mean+se, linetype="1"), width=0.3) +
 theme(legend.position = c(0.8,0.5)) +
 scale_y_continuous(name = "mean(Weight) +/- se(Weight)")
```

Each point corresponds to the mean weight of the group at a specific point in time, with the standard error shown as error bars. Just by eye, it can be seen that the slopes for group 2 and 3 are quite similar, while the slope for group 1 is less steep than for the other two.

The overall weight can be summarized with a summary measure. In the plot below, the mean weights for each group over the whole experiment period is shown.

```{r, echo=FALSE, message=FALSE}
RATSLS <- RATSL %>%
 group_by(Group, ID) %>%
 summarise( mean=mean(Weight) ) %>%
 ungroup()
```
```{r, fig.width = 6, fig.height = 5, echo=FALSE, warning=FALSE}
ggplot(RATSLS, aes(x = Group, y = mean)) +
  geom_boxplot() +
  stat_summary(fun.y = "mean", geom = "point", shape=23, size=4, fill = "white") +
  scale_y_continuous(name = "mean(Weight)")
```

To be honest, this particular summary measure is not good for this particular data set, as the starting point for each group is drastically different. Either the weights of the rats should be normalized so that the first measured weight would be of similar magnitude in all groups. And even then, perhaps a summary measure like regression coefficient would be more suitable for the data.

Doing a thorough analysis using the summary measure approach on this data set would require much more effort and time than I have right now, unfortunately.

### BPRS

In the second part, the data set consists of human subjects who were periodically rated on the brief psychiatric rating scale (BPRS). This data set is analyzed with linear mixed effects models to see how well they perform in terms of predicting BPRS values. Let's again start by having a look at the data set in the long form.


```{r, echo=FALSE}
str(BPRSL)
```

There are twenty subjects, and they were divided into two groups receiving different psychiatric treatment over eight weeks. The below plot visualizes how the BRPS ratings evolved during the treatment in the two groups.


```{r, fig.width = 6, fig.height = 5, echo=FALSE}
ggplot(BPRSL, aes(x = week, y = bprs, linetype = subject)) +
  geom_line() +
  scale_linetype_manual(values = rep(1:10, times=4)) +
  facet_grid(. ~ treatment, labeller = label_both) +
  theme(legend.position = "none") +
  scale_y_continuous(limits = c(min(BPRSL$bprs), max(BPRSL$bprs)))
```

Already simply by eye, it can be seen that both of the treatments work as they lower the average BPRS rating after 8 weeks of treatment. For a more quantitative analysis, regression models are fitted. First, we do the (incorrect) assumption that the observations are independent of each other and ignore the longitudinal aspect of the data set, and fit a linear regression model where the *BPRS* is the response variable, while *treatment* and *week* are the explanatory variables.


```{r, echo=FALSE}
BPRS_reg <- lm(bprs ~ week + treatment, data = BPRSL)

summary(BPRS_reg)
```

Obviously time is the critical factor that determines the variation in BPRS in this data set, so *week* is given high significance by the model, as one would expect. On the other hand, treatment does not give any predictive power as it has huge error relative to its estimated coefficient.

To get a better model for the data set, a random intercept model is fitted. The explanatory variables remain the same, but there is additional random effect attributed to each subject. 

```{r, echo=FALSE}
BPRS_ref <- lmer(bprs ~ week + treatment + (1 | subject), data = BPRSL, REML = FALSE)

summary(BPRS_ref)
```

A notable difference in comparison to the previous model is that now the standard error values for *week* and *treatment* are smaller. To take the analysis further with an even more flexible model, random slope is added on top of the random intercept. This allows the subjects to have different slopes as well.

```{r, echo=FALSE}
BPRS_ref1 <- lmer(bprs ~ week + treatment + (week | subject), data = BPRSL, REML = FALSE)

summary(BPRS_ref1)
```

To properly see if the random intercept+slope model is better than just the random intercept model, the models can be compared with ANOVA.

```{r, echo=FALSE}
anova(BPRS_ref1, BPRS_ref)
```

Since Pr(>Chisq) is around 0.026, we can say that the random intercept+slope model does perform better and adding the random slope to the model is justified.

To go still further, we can try if adding *treatment* * *week* interaction to the model produces even better results.


```{r, echo=FALSE}
BPRS_ref2 <- lmer(bprs ~ week + treatment + (week | subject) + week*treatment, data = BPRSL, REML = FALSE)

summary(BPRS_ref2)
```

This model can again be compared to the random intercept+slope model with ANOVA.


```{r, echo=FALSE}
anova(BPRS_ref2, BPRS_ref1)
```

This time around, Pr(>Chisq) is around 0.075, so it can be argued that adding the *treatment* * *week* interaction does not improve the model.

To conclude this analysis, let's compare the observed BPRS values to the fitted values for each subject given by the random intercept and slope model.

```{r, fig.width = 5, fig.height = 4, echo=FALSE, message=FALSE, warning=FALSE}
ggplot(BPRSL, aes(x = week, y = bprs, linetype = subject)) +
  geom_line() +
  facet_grid(. ~ treatment, labeller = label_both) +
  scale_x_continuous(name = "Time (weeks)") +
  scale_y_continuous(name = "Observed BPRS", limits = c(min(BPRSL$bprs), max(BPRSL$bprs))) + theme(legend.position = "none")
```

```{r, echo=FALSE}
Fitted <- fitted.values(BPRS_ref1)

BPRSL <- mutate(BPRSL, fitted = Fitted)
```

```{r, fig.width = 5, fig.height = 4, echo=FALSE, message=FALSE, warning=FALSE}
ggplot(BPRSL, aes(x = week, y = fitted, linetype = subject)) +
  geom_line() +
  scale_linetype_manual(values = rep(1:10, times=4)) +
  facet_grid(. ~ treatment, labeller = label_both) +
  scale_x_continuous(name = "Time (weeks)") +
  scale_y_continuous(name = "Fitted BPRS", limits = c(min(BPRSL$bprs), max(BPRSL$bprs))) + theme(legend.position = "none")
```

I would say that in the case of the first treatment where the variance in the subjects is not so great, the model works relatively well in predicting the BPRS values. The variance in the subjects belonging to the second treatment group is larger, so even with random intercept. the model cannot account for all that variance in the subjects. Just by looking at the models, no conclusions can be made as to which of the two treatments works better.